---
title: "GPT-OSS 120B"
sidebarTitle: "GPT-OSS 120B"
description: "OpenAI's open-weight 120B parameter language model for advanced text generation."
---

GPT-OSS 120B is OpenAI's open-weight 120B parameter language model, offering powerful text generation capabilities with advanced reasoning and instruction-following abilities.

<Card title="Try in playground" icon="play" href="https://console.runpod.io/hub/playground/text/gpt-oss-120b">
  Test GPT-OSS 120B in the Runpod Hub playground.
</Card>

| | |
|---|---|
| **Endpoint** | `https://api.runpod.ai/v2/gpt-oss-120b/runsync` |
| **Pricing** | $10.00 per 1M tokens |
| **Type** | Text generation |

<Note>
This endpoint is fully compatible with the OpenAI API. See the [OpenAI compatibility examples](#openai-api-compatibility) below.
</Note>

## Request

All parameters are passed within the `input` object in the request body.

<ParamField body="input.prompt" type="string" required>
  Prompt for text generation.
</ParamField>

<ParamField body="input.max_tokens" type="integer" default="512">
  Maximum number of tokens to output.
</ParamField>

<ParamField body="input.temperature" type="float" default="0.7">
  Randomness of the output. Lower values make output more predictable and deterministic. Range: 0.0-1.0.
</ParamField>

<ParamField body="input.top_p" type="float">
  Nucleus sampling threshold. Samples from the smallest set of words whose cumulative probability exceeds this threshold.
</ParamField>

<ParamField body="input.top_k" type="integer">
  Restricts sampling to the top K most probable words.
</ParamField>

<ParamField body="input.stop" type="string">
  Stops generation if the given string is encountered.
</ParamField>

<RequestExample>
```bash cURL
curl -X POST "https://api.runpod.ai/v2/gpt-oss-120b/runsync" \
  -H "Authorization: Bearer $RUNPOD_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": {
      "prompt": "Explain the concept of quantum entanglement in simple terms:",
      "max_tokens": 512,
      "temperature": 0.7
    }
  }'
```

```python Python
import requests

response = requests.post(
    "https://api.runpod.ai/v2/gpt-oss-120b/runsync",
    headers={
        "Authorization": f"Bearer {RUNPOD_API_KEY}",
        "Content-Type": "application/json",
    },
    json={
        "input": {
            "prompt": "Explain the concept of quantum entanglement in simple terms:",
            "max_tokens": 512,
            "temperature": 0.7,
        }
    },
)

result = response.json()
print(result["output"])
```

```javascript JavaScript
const response = await fetch(
  "https://api.runpod.ai/v2/gpt-oss-120b/runsync",
  {
    method: "POST",
    headers: {
      Authorization: `Bearer ${RUNPOD_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      input: {
        prompt: "Explain the concept of quantum entanglement in simple terms:",
        max_tokens: 512,
        temperature: 0.7,
      },
    }),
  }
);

const result = await response.json();
console.log(result.output);
```
</RequestExample>

## Response

<ResponseField name="id" type="string">
  Unique identifier for the request.
</ResponseField>

<ResponseField name="status" type="string">
  Request status. Returns `COMPLETED` on success, `FAILED` on error.
</ResponseField>

<ResponseField name="delayTime" type="integer">
  Time in milliseconds the request spent in queue before processing began.
</ResponseField>

<ResponseField name="executionTime" type="integer">
  Time in milliseconds the model took to generate the response.
</ResponseField>

<ResponseField name="output" type="object">
  The generation result containing the text and usage information.

  <ResponseField name="output.choices" type="array">
    Array containing the generated text.
  </ResponseField>

  <ResponseField name="output.cost" type="float">
    Cost of the generation in USD.
  </ResponseField>

  <ResponseField name="output.usage" type="object">
    Token usage information with `input` and `output` counts.
  </ResponseField>
</ResponseField>

<ResponseExample>
```json 200
{
  "delayTime": 30,
  "executionTime": 4521,
  "id": "sync-a1b2c3d4-e5f6-7890-abcd-ef1234567890-u1",
  "output": [
    {
      "choices": [
        {
          "tokens": [
            "Quantum entanglement is a phenomenon where two particles become connected in such a way that measuring one particle instantly affects the other, no matter how far apart they are..."
          ]
        }
      ],
      "cost": 0.005,
      "usage": {
        "input": 15,
        "output": 485
      }
    }
  ],
  "status": "COMPLETED"
}
```
</ResponseExample>

## OpenAI API compatibility

GPT-OSS 120B is fully compatible with the OpenAI API format. You can use the OpenAI Python client to interact with this endpoint.

```python Python (OpenAI SDK)
from openai import OpenAI

client = OpenAI(
    api_key=RUNPOD_API_KEY,
    base_url="https://api.runpod.ai/v2/gpt-oss-120b/openai/v1",
)

response = client.chat.completions.create(
    model="gpt-oss-120b",
    messages=[
        {
            "role": "system",
            "content": "You are a helpful assistant.",
        },
        {
            "role": "user",
            "content": "Explain the concept of quantum entanglement in simple terms.",
        },
    ],
    max_tokens=512,
)

print(response.choices[0].message.content)
```

For streaming responses, add `stream=True`:

```python Python (Streaming)
response = client.chat.completions.create(
    model="gpt-oss-120b",
    messages=[
        {"role": "user", "content": "Write a short story about space exploration."}
    ],
    max_tokens=512,
    stream=True,
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

For more details, see [Send vLLM requests](/serverless/vllm/vllm-requests) and the [OpenAI API compatibility guide](/serverless/vllm/openai-compatibility).

## Cost calculation

GPT-OSS 120B charges $10.00 per 1M tokens. Example costs:

| Tokens | Cost |
|--------|------|
| 1,000 tokens | $0.01 |
| 10,000 tokens | $0.10 |
| 100,000 tokens | $1.00 |
| 1,000,000 tokens | $10.00 |
