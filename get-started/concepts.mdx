---
title: "Concepts"
description: "Key concepts and terminology for understanding Runpod's platform and products."
---

## [Runpod console](https://console.runpod.io)

The web interface for managing your compute resources, account, teams, and billing.

## Container

A Docker-based environment that packages your code, dependencies, and runtime into a portable unit that runs consistently across machines.

## Data center

Physical facilities where Runpod's GPU and CPU hardware is located. Your choice of data center can affect latency, available GPU types, and pricing.

## Machine

The physical server hardware within a data center that hosts your workloads. Each machine contains CPUs, GPUs, memory, and storage.

## [Serverless](/serverless/overview)

Serverless is a pay-as-you-go compute solution designed for dynamic autoscaling in production environments. It automatically adjusts computational resources based on your request traffic, ensuring cost-effective usage.

## [Pod](/pods/overview)

A dedicated GPU or CPU instance for containerized workloads. Pods are billed by the minute and stay available as long as you keep them running, making them perfect for development, training, and workloads that need continuous access.

## [Instant Cluster](/instant-clusters/overview)

A managed compute cluster with high-speed networking for multi-node distributed workloads like training large AI models. Includes automated configuration, static IP management, and pre-configured environment variables.

## [Public Endpoint](/hub/public-endpoints)

An AI model API hosted by Runpod that you can access directly without deploying your own infrastructure.

## [Network volume](/storage/network-volumes)

Persistent storage that exists independently of your other compute resources and can be attached to multiple Pods or Serverless endpoints, or moved between machines. Use network volumes to store datasets, models, and other data.

## [S3-compatible API](/storage/s3-api)
A storage interface compatible with Amazon S3 for uploading, downloading, and managing files in your network volumes. Use it for persistent storage of models, datasets, and outputs.

## [Runpod Hub](/hub/overview)

A repository for discovering, deploying, and sharing preconfigured AI projects optimized for Runpod. Includes one-click deployment of vetted open-source repositories.