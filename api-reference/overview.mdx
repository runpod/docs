---
title: "Overview"
description: "Use the Runpod API to programmatically manage your compute resources."
---

import { PodsTooltip, InferenceTooltip, ServerlessTooltip, NetworkVolumeTooltip, TemplatesTooltip } from "/snippets/tooltips.jsx";

The Runpod API provides programmatic access to all of Runpod's cloud compute resources. It enables you to integrate GPU infrastructure directly into your applications, workflows, and automation systems.

Use the Runpod API to:

* Create, monitor, and manage <PodsTooltip /> for persistent workloads.
* Deploy and scale <ServerlessTooltip /> endpoints for AI <InferenceTooltip />.
* Configure <NetworkVolumeTooltip /> for data persistence.
* Integrate Runpod's GPU computing power into your existing applications and CI/CD pipelines.

The API follows REST principles and returns JSON responses, making it compatible with virtually any programming language or automation tool. Whether you're building a machine learning platform, automating model deployments, or creating custom dashboards for resource management, the Runpod API provides a foundation for seamless integration.

## Available resources

The Runpod API provides complete access to Runpod's core resources:

* **Pods**: Create and manage persistent GPU instances for development, training, and long-running workloads. Control Pod lifecycles, configure hardware specifications, and manage SSH access programmatically.
* **Serverless endpoints**: Deploy and scale containerized applications for AI inference and batch processing. Configure autoscaling parameters, manage <WorkersTooltip /> pools, and monitor job execution in real-time.
* **Network volumes**: Create persistent storage that can be attached to multiple resources. Manage data persistence across Pod restarts and share datasets between different compute instances.
* **Templates**: Save and reuse Pod and endpoint configurations with <TemplatesTooltip /> to standardize deployments across projects and teams.
* **Container registry authentication**: Securely connect to private Docker registries to deploy custom containers and models.
* **Billing and usage**: Access detailed billing information and resource usage metrics to optimize costs and monitor spending across projects.

## Getting started

To use the REST API, you'll need a [Runpod API key](/get-started/api-keys) with appropriate permissions for the resources you want to manage. API keys can be generated and managed through your account settings in the Runpod console.

All API requests require authentication using your API key in the request headers. The API uses standard HTTP methods (GET, POST, PATCH, DELETE) and returns JSON responses with detailed error information when needed.

## Retrieve the OpenAPI schema

You can get the complete OpenAPI specification for the Runpod API using the `/openapi.json` endpoint. Use this to generate client libraries, validate requests, or integrate the API specification into your development tools.

The schema includes all available endpoints, request and response formats, authentication requirements, and data models.

<CodeGroup>

```bash cURL
curl --request GET \
  --url https://rest.runpod.io/v1/openapi.json \
  --header 'Authorization: Bearer RUNPOD_API_KEY'
```

```python Python
import requests

url = "https://rest.runpod.io/v1/openapi.json"
headers = {"Authorization": "Bearer RUNPOD_API_KEY"}
response = requests.get(url, headers=headers)
print(response.json())
```

</CodeGroup>

The endpoint returns the OpenAPI 3.0 specification in JSON format. You can use it with tools like Swagger UI, Postman, or code generation utilities.

For detailed endpoint documentation, request/response schemas, and code examples, explore the sections in the sidebar to the left.
