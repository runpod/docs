---
title: "Featured examples"
sidebarTitle: "Featured examples"
description: "Step-by-step guides for building and deploying AI applications on Runpod."
---

<Note>
This page includes our most recently tested and updated examples. Many of our old guides are out of date and include deprecated instructions. We're actively working on updating them.
</Note>

This section includes step-by-step guides to help you build and deploy example applications on the Runpod platform, covering basic concepts and advanced implementations.

## Get started

If you're new to Runpod, start with these foundational examples to understand the platform and deploy your first application:

<CardGroup cols={2}>
  <Card title="Create an image generation endpoint with Serverless" href="/tutorials/serverless/run-your-first" icon="cloud-bolt" iconType="solid">
    Deploy a Stable Diffusion endpoint and generate your first AI image using Serverless.
  </Card>
  <Card title="Run LLM inference on Pods with JupyterLab" href="/tutorials/pods/run-your-first" icon="text-size" iconType="solid">
    Launch JupyterLab on a GPU Pod and run LLM inference using the Python `transformers` library.
  </Card>
</CardGroup>

## Deploy ComfyUI

Learn how to deploy ComfyUI on Serverless or Pods and generate images with text-to-image models.

<CardGroup cols={2}>
  <Card title="Generate images with ComfyUI on Serverless" href="/tutorials/serverless/comfyui" icon="brackets-curly" iconType="solid">
    Deploy ComfyUI on Serverless and generate images using JSON workflows.
  </Card>
  <Card title="Generate images with ComfyUI on Pods" href="/tutorials/pods/comfyui" icon="images" iconType="solid">
    Deploy ComfyUI on a GPU Pod and generate images using the ComfyUI web interface.
  </Card>
</CardGroup>