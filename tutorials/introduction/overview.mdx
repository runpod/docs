---
title: "Featured tutorials"
sidebarTitle: "Featured tutorials"
description: "Learn how to build and deploy AI applications on Runpod with step-by-step tutorials."
---

This section includes tutorials that will help you build and deploy specialized AI applications on the Runpod platform, covering basic concepts and advanced implementations.

## Getting started

New to Runpod? Start with these foundational tutorials to understand the platform and deploy your first application.

<CardGroup cols={2}>
  <Card title="Generate an image with Serverless" href="/tutorials/serverless/run-your-first" icon="cloud-bolt">
    Deploy a Stable Diffusion endpoint and generate your first AI image using Serverless.
  </Card>
  <Card title="Generate an image with JupyterLab" href="/tutorials/pods/run-your-first" icon="server">
    Launch a Jupyter Notebook on a GPU Pod and run Fast Stable Diffusion.
  </Card>
</CardGroup>

## Serverless tutorials

Learn to build and deploy scalable AI applications with Runpod's Serverless platform.

### Image generation

<CardGroup cols={2}>
  <Card title="Generate images with SDXL Turbo" href="/tutorials/serverless/generate-sdxl-turbo" icon="image">
    Build a fast text-to-image application using SDXL Turbo and Serverless Workers.
  </Card>
  <Card title="Deploy Stable Diffusion" href="/tutorials/serverless/run-your-first" icon="palette">
    Set up a Stable Diffusion inference endpoint for image generation.
  </Card>
</CardGroup>

### Language models

<CardGroup cols={2}>
  <Card title="Deploy Google's Gemma model" href="/tutorials/serverless/run-gemma-7b" icon="brain">
    Run Google's Gemma-7b model using vLLM Worker with OpenAI-compatible APIs.
  </Card>
  <Card title="Run Ollama on CPU" href="/tutorials/serverless/run-ollama-inference" icon="microchip">
    Set up an Ollama server on Runpod CPU for efficient language model inference.
  </Card>
</CardGroup>

## Pod tutorials

Discover how to use Runpod Pods for development, training, and running AI applications on dedicated GPU instances.

### AI model deployment

<CardGroup cols={2}>
  <Card title="Generate images with ComfyUI" href="/tutorials/pods/comfyui" icon="image">
    Deploy ComfyUI on a GPU Pod and create AI images with node-based workflows.
  </Card>
  <Card title="Run Fooocus" href="/tutorials/pods/run-fooocus" icon="sparkles">
    Set up Fooocus image generation in Jupyter Notebook with minimal GPU requirements.
  </Card>
</CardGroup>

### Model training and fine-tuning

<CardGroup cols={2}>
  <Card title="Fine-tune LLMs with Axolotl" href="/tutorials/pods/fine-tune-llm-axolotl" icon="graduation-cap">
    Learn to fine-tune large language models using Axolotl on Runpod GPUs.
  </Card>
  <Card title="Set up Ollama on GPU" href="/tutorials/pods/run-ollama" icon="zap">
    Deploy Ollama on a GPU Pod for accelerated language model inference.
  </Card>
</CardGroup>

### Development tools

<CardGroup cols={1}>
  <Card title="Build Docker images with Bazel" href="/tutorials/pods/build-docker-images" icon="docker">
    Use Bazel to build Docker images directly on Runpod Pods.
  </Card>
</CardGroup>

## Container fundamentals

Master Docker containers and containerization concepts essential for Runpod development.

<CardGroup cols={2}>
  <Card title="Container basics" href="/tutorials/introduction/containers" icon="cube">
    Learn Docker fundamentals and containerization concepts.
  </Card>
  <Card title="Create Dockerfiles" href="/tutorials/introduction/containers/create-dockerfiles" icon="file-code">
    Build custom Docker images with Dockerfiles and entrypoint scripts.
  </Card>
  <Card title="Persist data with volumes" href="/tutorials/introduction/containers/persist-data" icon="database">
    Use Docker volumes to persist data across container lifecycles.
  </Card>
  <Card title="Docker command reference" href="/tutorials/introduction/containers/docker-commands" icon="terminal">
    Essential Docker commands for Runpod development workflows.
  </Card>
</CardGroup>

## SDK tutorials

Build applications programmatically using Runpod's Python SDK.

### Python SDK basics

<CardGroup cols={2}>
  <Card title="Hello world" href="/tutorials/sdks/python/get-started/hello-world" icon="code">
    Create your first Serverless function with the Python SDK.
  </Card>
  <Card title="Local testing" href="/tutorials/sdks/python/101/local-server-testing" icon="flask">
    Test your Serverless functions locally before deployment.
  </Card>
</CardGroup>

### Advanced patterns

<CardGroup cols={2}>
  <Card title="Generator functions" href="/tutorials/sdks/python/101/generator" icon="arrows-rotate">
    Build streaming Serverless functions that yield incremental results.
  </Card>
  <Card title="Async handlers" href="/tutorials/sdks/python/101/async" icon="bolt">
    Create asynchronous handlers for concurrent processing.
  </Card>
  <Card title="Error handling" href="/tutorials/sdks/python/101/error" icon="triangle-exclamation">
    Implement robust error handling and logging in your functions.
  </Card>
  <Card title="Result aggregation" href="/tutorials/sdks/python/101/aggregate" icon="layer-group">
    Automatically collect and aggregate results from generator functions.
  </Card>
</CardGroup>

### AI model integration

<CardGroup cols={2}>
  <Card title="Hugging Face models" href="/tutorials/sdks/python/102/huggingface-models" icon="hugging-face">
    Integrate Hugging Face transformers for sentiment analysis and NLP tasks.
  </Card>
  <Card title="Stable Diffusion" href="/tutorials/sdks/python/102/stable-diffusion-text-to-image" icon="image">
    Build a text-to-image service using Stable Diffusion and the Python SDK.
  </Card>
</CardGroup>

## Integrations and migrations

Connect Runpod with external tools and migrate from other platforms.

### Third-party integrations

<CardGroup cols={3}>
  <Card title="OpenAI SDK" href="/tutorials/migrations/openai/overview" icon="openai">
    Use OpenAI SDK with Runpod Serverless endpoints.
  </Card>
  <Card title="SkyPilot" href="/integrations/skypilot" icon="plane">
    Deploy Runpod resources using SkyPilot framework.
  </Card>
  <Card title="Mods" href="/integrations/mods" icon="terminal">
    Integrate Runpod with Charm's Mods command-line tool.
  </Card>
</CardGroup>

### Platform migrations

<CardGroup cols={2}>
  <Card title="From Replicate (Cog)" href="/tutorials/migrations/cog/overview" icon="arrow-right">
    Migrate Cog models from Replicate to Runpod Serverless.
  </Card>
  <Card title="From Banana" href="/tutorials/migrations/banana/overview" icon="arrow-right">
    Transition from Banana to Runpod with Docker compatibility.
  </Card>
</CardGroup>

## Next steps

Ready to dive deeper? Explore these resources to expand your Runpod knowledge:

- **[Serverless documentation](/serverless/overview)**: Learn about endpoints, workers, and deployment options.
- **[Pod documentation](/pods/overview)**: Understand Pod configurations, storage, and networking.
- **[API reference](/api-reference)**: Explore Runpod's REST API for programmatic access.
- **[SDK documentation](/sdks/python/overview)**: Master the Python, JavaScript, and Go SDKs.