---
title: "Overview"
sidebarTitle: "Overview"
description: "Step-by-step guides for building and deploying AI/ML applications on Runpod."
---

This section includes step-by-step guides to help you build and deploy example applications on the Runpod platform, covering basic concepts and advanced implementations.

## Serverless

<CardGroup cols={2}>
  <Card title="Create an image generation endpoint with Serverless" href="/tutorials/serverless/run-your-first" icon="image" iconType="solid">
    Deploy a Stable Diffusion endpoint and generate your first AI image using Serverless.
  </Card>
  <Card title="Integrate Serverless with a web application" href="/tutorials/serverless/generate-sdxl-turbo" icon="brackets-curly" iconType="solid">
    Deploy an image generation endpoint and integrate it into a web application.
  </Card>
  <Card title="Deploy a cached model" href="/tutorials/serverless/model-caching-text" icon="server" iconType="solid">
    Learn how to create a custom Serverless endpoint that uses model caching to serve a large language model with reduced cost and cold start times.
  </Card>
  <Card title="Deploy a chatbot with Gemma 3 and send requests using the OpenAI API" href="/tutorials/serverless/run-gemma-7b" icon="right-left" iconType="solid">
    Deploy a Serverless endpoint with Google's Gemma 3 model using vLLM and the OpenAI API to build an interactive chatbot.
  </Card>
    <Card title="Generate images with ComfyUI on Serverless" href="/tutorials/serverless/comfyui" icon="images" iconType="solid">
    Deploy ComfyUI on Serverless and generate images using JSON workflows.
  </Card>

</CardGroup>


## Pods

<CardGroup cols={2}>
  <Card title="Run LLM inference on Pods with JupyterLab" href="/tutorials/pods/run-your-first" icon="text-size" iconType="solid">
    Launch JupyterLab on a GPU Pod and run LLM inference using the Python `transformers` library.
  </Card>
  <Card title="Pods + Ollama" href="/tutorials/pods/run-ollama" icon="terminal" iconType="solid">
    Deploy Ollama on a GPU Pod and run LLM inference using the Ollama API.
  </Card>
  <Card title="Build Docker images on Pods using Bazel" href="/tutorials/pods/build-docker-images" icon="docker" iconType="solid">
    Build Docker images on Pods using Bazel.
  </Card>
  <Card title="Generate images with ComfyUI on Pods" href="/tutorials/pods/comfyui" icon="images" iconType="solid">
    Deploy ComfyUI on a GPU Pod and generate images using the ComfyUI web interface.
  </Card>
</CardGroup>

## Public Endpoints

<CardGroup cols={2}>
  <Card title="Build a text-to-video pipeline" href="/tutorials/public-endpoints/text-to-video-pipeline" icon="video" iconType="solid">
    Chain multiple Public Endpoints to generate videos from text prompts using Python.
  </Card>
</CardGroup>
