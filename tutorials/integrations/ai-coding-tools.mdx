---
title: "Configure AI coding tools with Runpod endpoints"
sidebarTitle: "AI coding tools"
description: "Learn how to configure OpenCode, Cursor, and Cline to use Runpod's OpenAI-compatible LLM endpoints for AI-assisted coding."
---

Runpod's Public Endpoints provide OpenAI-compatible APIs that work with AI coding assistants. This tutorial shows you how to configure OpenCode, Cursor, and Cline to use Runpod's LLM endpoints.

## What you'll learn

- Configure OpenCode with Runpod's GPT OSS 120B and Qwen3 32B AWQ endpoints.
- Set up Cursor with a Runpod endpoint.
- Configure Cline in VS Code with both GPT OSS and Qwen3 endpoints.

## Requirements

- A Runpod account with an [API key](/get-started/api-keys).
- One of the following AI coding tools installed:
  - [OpenCode](https://opencode.ai/) - Terminal-based AI coding assistant.
  - [Cursor](https://cursor.sh/) - AI-powered code editor.
  - [Cline](https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev) - VS Code extension for AI-assisted coding.

## Available endpoints

This tutorial uses two Runpod Public Endpoints that work with AI coding tools:

| Model | Base URL | Model ID | Context window |
|-------|----------|----------|----------------|
| GPT OSS 120B | `https://api.runpod.ai/v2/gpt-oss-120b/openai/v1` | `openai/gpt-oss-120b` | 131,072 tokens |
| Qwen3 32B AWQ | `https://api.runpod.ai/v2/qwen3-32b-awq/openai/v1` | `Qwen/Qwen3-32B-AWQ` | 32,768 tokens |

Both endpoints follow the OpenAI API specification, so they work with any tool that supports custom OpenAI-compatible providers.

## Step 1: Configure OpenCode

OpenCode supports multiple provider configurations, so you can set up both Runpod endpoints and switch between them.

### Create the config directory

OpenCode looks for its config at `~/.config/opencode/opencode.json`. Create the directory if it doesn't exist:

```bash
mkdir -p ~/.config/opencode
```

### Create the config file

Create `~/.config/opencode/opencode.json` with the following content:

```json
{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "runpod-gpt": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "RunPod GPT OSS 120B",
      "options": {
        "baseURL": "https://api.runpod.ai/v2/gpt-oss-120b/openai/v1",
        "apiKey": "{env:RUNPOD_API_KEY}"
      },
      "models": {
        "gpt-oss-120b": {
          "id": "openai/gpt-oss-120b",
          "name": "GPT OSS 120B (RunPod)",
          "limit": { "context": 131072, "output": 4096 }
        }
      }
    },
    "runpod-qwen": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "RunPod Qwen3",
      "options": {
        "baseURL": "https://api.runpod.ai/v2/qwen3-32b-awq/openai/v1",
        "apiKey": "{env:RUNPOD_API_KEY}"
      },
      "models": {
        "qwen3-32b": {
          "id": "Qwen/Qwen3-32B-AWQ",
          "name": "Qwen3 32B AWQ (RunPod)",
          "limit": { "context": 32768, "output": 4096 }
        }
      }
    }
  }
}
```

The `{env:RUNPOD_API_KEY}` syntax tells OpenCode to read your API key from the `RUNPOD_API_KEY` environment variable. Set it in your shell:

```bash
export RUNPOD_API_KEY="rpa_YOUR_API_KEY"
```

<Tip>

Add the export command to your shell profile (`~/.bashrc`, `~/.zshrc`, etc.) so you don't need to set it every time.

</Tip>

## Step 2: Configure Cursor

Cursor supports a single global OpenAI-compatible endpoint override, so you can only use one Runpod endpoint at a time. GPT OSS 120B is recommended for its larger context window.

<Warning>

The Qwen3 32B AWQ endpoint is not compatible with Cursor.

</Warning>

<Steps>
  <Step title="Open Cursor settings">
    Launch Cursor and press `Cmd + ,` (macOS) or `Ctrl + ,` (Windows/Linux) to open Settings.
  </Step>

  <Step title="Navigate to model settings">
    Go to **Cursor Settings > Models** or search for "OpenAI" in the settings search bar.
  </Step>

  <Step title="Enter your API key">
    Find the **OpenAI API Key** field and enter your Runpod API key:
    ```
    rpa_YOUR_API_KEY
    ```
  </Step>

  <Step title="Set the base URL">
    Enable **Override OpenAI Base URL** and enter:
    ```
    https://api.runpod.ai/v2/gpt-oss-120b/openai/v1
    ```
  </Step>

  <Step title="Add the model">
    Click **+ Add Model** and enter the model ID exactly as shown (case-sensitive):
    ```
    openai/gpt-oss-120b
    ```
  </Step>

  <Step title="Select the model">
    Select `openai/gpt-oss-120b` from the model list when using Cursor's AI features.
  </Step>
</Steps>

## Step 3: Configure Cline

Cline is a VS Code extension with its own settings panel. Unlike Cursor, Cline supports multiple provider profiles, so you can configure both Runpod endpoints and switch between them.

### Install Cline

<Steps>
  <Step title="Open VS Code extensions">
    In VS Code, press `Cmd + Shift + X` (macOS) or `Ctrl + Shift + X` (Windows/Linux) to open the Extensions panel.
  </Step>

  <Step title="Install the extension">
    Search for "Cline" and click **Install**.
  </Step>
</Steps>

### Configure via the settings UI

<Steps>
  <Step title="Open Cline settings">
    Click the Cline icon in the sidebar to open the Cline panel, then click the gear icon to open Settings.
  </Step>

  <Step title="Select the API provider">
    Set **API Provider** to **OpenAI Compatible**.
  </Step>

  <Step title="Enter the connection settings">
    Fill in the following fields:

    | Setting | Value |
    |---------|-------|
    | Base URL | `https://api.runpod.ai/v2/gpt-oss-120b/openai/v1` |
    | API Key | `rpa_YOUR_API_KEY` |
    | Model ID | `openai/gpt-oss-120b` |
  </Step>

  <Step title="Save the configuration">
    Click **Save** to apply your settings.
  </Step>
</Steps>

To use Qwen3 instead, use these values:

| Setting | Value |
|---------|-------|
| Base URL | `https://api.runpod.ai/v2/qwen3-32b-awq/openai/v1` |
| Model ID | `Qwen/Qwen3-32B-AWQ` |

### Configure via settings.json

Alternatively, you can configure Cline directly in your VS Code `settings.json`:

```json
{
  "cline.apiProvider": "openai-compatible",
  "cline.openaiCompatibleBaseUrl": "https://api.runpod.ai/v2/gpt-oss-120b/openai/v1",
  "cline.openaiCompatibleApiKey": "rpa_YOUR_API_KEY",
  "cline.openaiCompatibleModelId": "openai/gpt-oss-120b"
}
```

## Tool comparison

| Feature | OpenCode | Cursor | Cline |
|---------|----------|--------|-------|
| Multiple providers | Yes | No | Yes |
| GPT OSS 120B support | Yes | Yes | Yes |
| Qwen3 32B support | Yes | No | Yes |
| Config method | JSON file | UI | UI or JSON |

## Next steps

- Learn more about [Public Endpoints](/hub/public-endpoints) and available models.
- See the [Public Endpoint model reference](/hub/public-endpoint-reference) for model-specific parameters.
- Create your own [API keys](/get-started/api-keys) for authentication.
