---
title: Slurm Clusters
sidebarTitle: Slurm Clusters
description: Deploy fully managed Slurm Clusters on Runpod with zero configuration
tag: "NEW"
---

Runpod Slurm Clusters provide a fully managed high-performance computing (HPC) scheduling solution that enables you to create, scale, and manage Slurm Clusters without the complexity of setup and configuration.

Slurm Clusters eliminate the traditional complexity of HPC cluster orchestration by providing:

- **Zero configuration setup:** Slurm is pre-installed and fully configured.
- **Instant provisioning:** Clusters deploy rapidly with minimal setup.
- **Automatic role assignment:** Runpod automatically designates controller and worker nodes.
- **Built-in optimizations:** Pre-configured for optimal NCCL performance.
- **Full Slurm compatibility:** All standard Slurm commands work out-of-the-box.

This page shows how to deploy a Slurm Cluster on Runpod, and how to use it to run distributed training jobs.

<Tip>

If you would rather configure and manage an Instant Cluster with Slurm manually, see [Deploy an Instant Cluster with Slurm](/instant-clusters/slurm) for a step-by-step guide.

</Tip>

## Creating a Slurm Cluster

1. Navigate to the [Runpod Instant Clusters console](https://console.runpod.io/cluster).
2. Click **Create Cluster**.
3. Select **Slurm Cluster** from the cluster type options.
4. Configure your cluster specifications.
5. Click **Deploy Cluster**.

## Accessing your cluster

Once deployment completes, view your cluster dashboard. The interface clearly displays:
- Controller node (primary node) with its connection details
- Worker nodes with their status and specifications
- Overall cluster health and resource availability

SSH directly into the controller node using the provided credentials:

```bash
ssh username@controller-node-address
```

No additional setup is required - Slurm is ready to use immediately upon connection.

## Submit and manage jobs

All standard Slurm commands are available without configuration:

Check cluster status and available resources:
```bash
sinfo
```

Submit a job to the cluster:
```bash
sbatch your-job-script.sh
```

Monitor job queue and status:
```bash
squeue
```

View detailed job information:
```bash
scontrol show job <job-id>
```

The managed environment includes:
- Pre-installed Slurm with all necessary plugins
- Configured Munge authentication
- Optimized topology.conf for NCCL performance
- Support for common HPC workloads and MPI integration

## Advanced configuration

While the managed Slurm cluster works out-of-the-box, advanced users can customize configurations through shell access.

Access Slurm configuration files in their standard locations:
- `/etc/slurm/slurm.conf` - Main configuration file
- `/etc/slurm/topology.conf` - Network topology configuration
- `/etc/slurm/gres.conf` - Generic resource configuration

Modify these files as needed for your specific requirements. The managed service ensures baseline functionality while allowing flexibility for customization.

## Performance optimization

Managed Slurm clusters come pre-optimized for distributed training workloads:

- **Topology-aware scheduling** - Properly configured topology.conf ensures optimal NCCL performance
- **GPU resource management** - Automatic GRES configuration for GPU scheduling
- **MPI integration** - Pre-configured for seamless MPI job execution

These optimizations enable efficient large-scale ML training without manual tuning.

## Monitoring and scaling

Monitor your cluster health and resource utilization through the Runpod dashboard. Key metrics include:
- Node availability and status
- Job queue statistics
- Resource utilization trends

Scale your cluster based on workload demands by adding or removing nodes through the Instant Clusters interface. The managed service handles all reconfiguration automatically.

## Best practices

To maximize the effectiveness of your managed Slurm cluster:

- Start with the minimum nodes required and scale as needed
- Use Slurm's built-in accounting features to track resource usage
- Leverage job arrays for similar tasks to improve scheduling efficiency
- Monitor job performance metrics to optimize resource allocation

## Troubleshooting

If you encounter issues with your managed Slurm cluster:

**Jobs stuck in pending state**
Check resource availability with `sinfo` and ensure requested resources are available.

**Authentication errors**
Munge is pre-configured, but if issues arise, verify the munge service is running on all nodes.

**Performance issues**
Review topology configuration and ensure jobs are using appropriate resource requests.

For additional support, contact Runpod support with your cluster ID and specific error messages.