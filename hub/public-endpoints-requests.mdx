---
title: "Make API requests"
sidebarTitle: "Make API requests"
description: "Use the playground, REST API, and SDKs to interact with Public Endpoints."
---

This guide covers all the ways to interact with Public Endpoints, from testing in the browser to integrating with your applications. For an introduction to Public Endpoints, see the [overview](/hub/public-endpoints).

## Requirements

- A [Runpod account](/get-started/manage-accounts) with credits
- A [Runpod API key](/get-started/api-keys) for making API requests

## Use the playground

The Public Endpoint playground lets you test models directly in your browser before writing any code.

<Frame alt="Public Endpoint playground">
  <img src="/images/public-endpoint-playground.png" />
</Frame>

The playground offers:

- **Interactive parameter adjustment**: Modify prompts, dimensions, and model settings in real-time.
- **Instant preview**: Generate images directly in the browser.
- **Cost estimation**: See estimated costs before running generation.
- **API code generation**: Create working code examples for your applications.

### Access the playground

1. Navigate to the [Runpod Hub](https://www.runpod.io/console/hub) in the console.
2. Select the **Public Endpoints** section.
3. Browse the available models and select one that fits your needs.

### Test a model

1. Select a model from the [Runpod Hub](https://www.console.runpod.io/hub).
2. Under **Input**, enter a prompt in the text box.
3. Enter a negative prompt if needed. Negative prompts tell the model what to exclude from the output.
4. Under **Additional settings**, you can adjust the seed, aspect ratio, number of inference steps, guidance scale, and output format.
5. Click **Run** to start generating.

Under **Result**, you can use the dropdown menu to show either a preview of the output, or the raw JSON.

### Generate code from the playground

<Frame alt="Public Endpoint code example">
  <img src="/images/public-endpoint-api-playground.png" />
</Frame>

After testing a model in the playground, you can automatically generate an API request to use in your application.

1. Click **API Playground** (above the **Prompt** field).
2. Using the dropdown menu, select the programming language (Python, JavaScript, cURL, etc.) and POST command you want to use (`/run` or `/runsync`).
3. Click the **Copy** icon to copy the code to your clipboard.

## Make API requests

You can make API requests to Public Endpoints using any HTTP client. All requests require authentication using your Runpod API key, passed in the `Authorization` header.

<Tip>
To learn more about the difference between synchronous and asynchronous requests, see [Endpoint operations](/serverless/endpoints/send-requests).
</Tip>

### Synchronous requests

Synchronous requests (`/runsync`) wait for the model to finish processing and return the result directly. Use these for quick generations where you want an immediate response.

```bash cURL
curl -X POST "https://api.runpod.ai/v2/black-forest-labs-flux-1-dev/runsync" \
  -H "Authorization: Bearer RUNPOD_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": {
      "prompt": "A serene mountain landscape at sunset",
      "width": 1024,
      "height": 1024,
      "num_inference_steps": 20,
      "guidance": 7.5
    }
  }'
```

### Asynchronous requests

Asynchronous requests (`/run`) return immediately with a job ID. Use these for longer generations or when you want to queue multiple requests.

```bash cURL
curl -X POST "https://api.runpod.ai/v2/black-forest-labs-flux-1-dev/run" \
  -H "Authorization: Bearer RUNPOD_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": {
      "prompt": "A futuristic cityscape with flying cars",
      "width": 1024,
      "height": 1024,
      "num_inference_steps": 50,
      "guidance": 8.0
    }
  }'
```

Check the status and retrieve results using the `/status` endpoint, replacing `{job-id}` with the job ID returned from the `/run` request:

```bash cURL
curl -X GET "https://api.runpod.ai/v2/black-forest-labs-flux-1-dev/status/{job-id}" \
  -H "Authorization: Bearer RUNPOD_API_KEY"
```

### Response format

All endpoints return a consistent JSON response format:

```json
{
  "delayTime": 17,
  "executionTime": 3986,
  "id": "sync-0965434e-ff63-4a1c-a9f9-5b705f66e176-u2",
  "output": {
    "cost": 0.02097152,
    "image_url": "https://image.runpod.ai/..."
  },
  "status": "COMPLETED",
  "workerId": "oqk7ao1uomckye"
}
```

<Warning>
Output URLs (`image_url`, `video_url`, and `audio_url`) expire after 7 days. Download and store your generated files immediately if you need to keep them longer.
</Warning>

## SDK integrations

### Python

```python
import requests

headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer RUNPOD_API_KEY"
}

data = {
    "input": {
        "prompt": "A serene mountain landscape at sunset",
        "image_format": "png",
        "num_inference_steps": 25,
        "guidance": 7,
        "seed": 50,
        "width": 1024,
        "height": 1024,
    }
}

response = requests.post(
    "https://api.runpod.ai/v2/black-forest-labs-flux-1-dev/run",
    headers=headers,
    json=data,
)

print(response.json())
```

### JavaScript/TypeScript with Vercel AI SDK

For JavaScript and TypeScript projects, you can use the `@runpod/ai-sdk-provider` package to integrate Public Endpoints with the [Vercel AI SDK](https://ai-sdk.dev/docs/introduction).

```bash
npm install @runpod/ai-sdk-provider ai
```

For text generation:

```typescript
import { runpod } from '@runpod/ai-sdk-provider';
import { generateText } from 'ai';

const { text } = await generateText({
  model: runpod('qwen3-32b-awq'),
  prompt: 'Write a Python function that sorts a list:',
});
```

For image generation:

```typescript
import { runpod } from '@runpod/ai-sdk-provider';
import { experimental_generateImage as generateImage } from 'ai';

const { image } = await generateImage({
  model: runpod.imageModel('flux/flux-dev'),
  prompt: 'A serene mountain landscape at sunset',
  aspectRatio: '4:3',
});
```

For comprehensive documentation and examples, see the [Node package documentation](https://www.npmjs.com/package/@runpod/ai-sdk-provider).

## Best practices

### Prompt engineering

- **Be specific**: Detailed prompts generally produce better results.
- **Include style modifiers**: Specify art styles, camera angles, or lighting conditions.
- **Use negative prompts**: For Flux Dev, exclude unwanted elements from your images.

A good prompt example: "A professional portrait of a woman in business attire, studio lighting, high quality, detailed, corporate headshot style."

### Performance optimization

- **Choose the right model**: Use Flux Schnell for speed, Flux Dev for quality.
- **Use standard dimensions**: 1024x1024 renders fastest.
- **Batch with async**: For multiple images, use `/run` to queue requests.
- **Cache results**: Store generated images to avoid regenerating identical prompts.

## Next steps

- [Model reference](/hub/public-endpoint-reference): View all available models and their parameters.
- [Connect AI coding tools](/hub/ai-coding-tools): Configure Cursor, Cline, and OpenCode with Public Endpoints.
- [Build custom endpoints](/serverless/overview): Deploy your own models with Runpod Serverless.
