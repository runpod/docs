---
title: "Welcome to Runpod"
description: "Explore our guides and examples to deploy your AI/ML application on Runpod."
sidebarTitle: "Welcome"
---
import { TrainingTooltip, FineTuningTooltip, InferenceTooltip } from "/snippets/tooltips.jsx";

Runpod is a cloud computing platform built for AI, machine learning, and general compute needs. Whether you're <TrainingTooltip /> or <FineTuningTooltip /> AI models, or deploying cloud-based applications for <InferenceTooltip />, Runpod provides scalable, high-performance GPU and CPU resources to power your workloads.

## Get started

If you're new to Runpod, start here to learn the essentials and deploy your first GPU.

<CardGroup>
    <Card title="Quickstart" href="/get-started" icon="bolt" iconType="solid">
        Create an account, deploy your first GPU Pod, and use it to execute code.
    </Card>
    <Card title="Concepts" href="/get-started/concepts" icon="book" iconType="solid">
        Learn about the key concepts and terminology for the Runpod platform.
    </Card>
    <Card title="Create an API key" href="/get-started/api-keys" icon="key" iconType="solid">
        Create API keys to manage your access to Runpod resources.
    </Card>
    <Card title="Manage your account" href="/get-started/manage-accounts" icon="users" iconType="solid">
        Learn how to manage your account, teams, and billing.
    </Card>
</CardGroup>

You can also watch this video for a high-level overview of our products:

<iframe
  className="w-full aspect-video rounded-xl"
  src="https://www.youtube.com/embed/ij-lB2JcOmg?si=jqmsiHrl7bz2mmin"
  title="High-level overview of Runpod compute options"
  frameBorder="0"
  allow="fullscreen; accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>

## Serverless

Serverless provides pay-per-second computing with automatic scaling for production AI/ML apps. You only pay for actual compute time when your code runs, with no idle costs, making Serverless ideal for variable workloads and cost-efficient production deployments.

<CardGroup>
    <Card title="Introduction" href="/serverless/overview" icon="cloud" iconType="solid">
        Learn how Serverless works and how to deploy pre-configured endpoints.
    </Card>
    <Card title="Pricing" href="/serverless/pricing" icon="dollar-sign" iconType="solid">
        Learn how Serverless billing works and how to optimize your costs.
    </Card>
    <Card title="vLLM quickstart" href="/serverless/vllm/get-started" icon="cloud-bolt" iconType="solid">
        Deploy a large language model for text or image generation in minutes using vLLM.
    </Card>
    <Card title="Build your first worker" href="/serverless/workers/custom-worker" icon="code" iconType="solid">
        Build a custom worker and deploy it as a Serverless endpoint.
    </Card>
</CardGroup>

## Pods

Pods give you dedicated GPU or CPU instances for containerized AI/ML workloads. Pods are billed by the minute and stay available as long as you keep them running, making them perfect for development, training, and workloads that need continuous access.

<CardGroup>
    <Card title="Introduction" href="/pods/overview" icon="microchip" iconType="solid">
        Understand the components of a Pod and options for configuration.
    </Card>
    <Card title="Pricing" href="/pods/pricing" icon="dollar-sign" iconType="solid">
        Learn about Pod pricing options and how to optimize your costs.
    </Card>
    <Card title="Choose a Pod" href="/pods/choose-a-pod" icon="server" iconType="solid">
        Learn how to choose the right Pod for your workload.
    </Card>
    <Card title="Generate images with ComfyUI" href="/tutorials/pods/comfyui" icon="image" iconType="solid">
        Learn how to deploy a Pod with ComfyUI pre-installed and start generating images.
    </Card>
</CardGroup>

## Public Endpoints

Public Endpoints provide instant API access to pre-deployed AI models for image, video, audio, and text generation. No deployment or infrastructure required. You only pay for what you generate, making it easy to integrate AI capabilities into your applications.

<CardGroup>
    <Card title="Overview" href="/public-endpoints/overview" icon="cloud" iconType="solid">
        Learn how Public Endpoints work and when to use them.
    </Card>
    <Card title="Quickstart" href="/public-endpoints/quickstart" icon="bolt" iconType="solid">
        Generate your first image in under 5 minutes.
    </Card>
    <Card title="Make API requests" href="/public-endpoints/requests" icon="code" iconType="solid">
        Use the playground, REST API, and SDKs.
    </Card>
    <Card title="Model reference" href="/public-endpoints/reference" icon="book" iconType="solid">
        Browse available models and their parameters.
    </Card>
</CardGroup>

## Instant Clusters

Instant Clusters deliver fully managed multi-node compute clusters with high-speed networking (up to 3200 Gbps) for distributed workloads. Run multi-node training, fine-tune large language models, or scale inference across multiple GPUs working in parallel.

<CardGroup>
    <Card title="Overview" href="/instant-clusters" icon="network-wired" iconType="solid">
        Learn how Instant Clusters work and when to use them.
    </Card>
    <Card title="Configuration reference" href="/instant-clusters/configuration" icon="book" iconType="solid">
        Environment variables, network interfaces, and NCCL configuration.
    </Card>
    <Card title="Deploy a Slurm cluster" href="/instant-clusters/slurm-clusters" icon="splotch" iconType="solid">
        Set up managed Slurm for HPC workloads.
    </Card>
    <Card title="Deploy a PyTorch cluster" href="/instant-clusters/pytorch" icon="fire" iconType="solid">
        Run distributed PyTorch training across multiple nodes.
    </Card>
</CardGroup>

## Support

<CardGroup>
    <Card title="Contact" href="https://contact.runpod.io" icon="headset" iconType="solid">
        Submit a support request using our contact page.
    </Card>
    <Card title="Email" href="mailto:help@runpod.io" icon="envelope" iconType="solid">
        Email help@runpod.io for direct support.
    </Card>
    <Card title="Status page" href="https://uptime.runpod.io/" icon="chart-line" iconType="solid">
        Check the status of Runpod services and infrastructure.
    </Card>
    <Card title="Discord" href="https://discord.gg/cUpRmau42V" icon="discord">
        Join the Runpod community on Discord.
    </Card>
</CardGroup>
