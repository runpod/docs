---
title: "Welcome to RunPod"
sidebarTitle: "Introduction"
---

RunPod is a cloud computing platform built for AI, machine learning, and general compute needs. Whether you're running deep learning models, training AI, or deploying cloud-based applications, RunPod provides scalable, high-performance GPU and CPU resources to power your workloads.

## Get started

If youâ€™re new to RunPod, start here to learn the essentials and deploy your first GPU.

<CardGroup>
    <Card title="Quickstart" href="/get-started" icon="bolt" iconType="solid">
        Create an account, deploy your first GPU Pod, and use it to execute code.
    </Card>
    <Card title="Manage accounts" href="/get-started/manage-accounts" icon="users" iconType="solid">
        Learn how to manage your personal and team accounts and set up permissions.
    </Card>
    <Card title="Create an API key" href="/get-started/api-keys" icon="key" iconType="solid">
        Create API keys to manage your access to RunPod resources.
    </Card>
    <Card title="Connection options" href="/get-started/connect-to-runpod" icon="plug" iconType="solid">
        Learn about different methods for connecting to RunPod and managing resources.
    </Card>
</CardGroup>

## Serverless

Serverless offers pay-per-second serverless computing with built-in autoscaling for production workloads.

<CardGroup>
    <Card title="Introduction" href="/serverless/overview" icon="cloud" iconType="solid">
        Learn how Serverless works and how to deploy pre-configured endpoints.
    </Card>
    <Card title="Pricing" href="/serverless/pricing" icon="dollar-sign" iconType="solid">
        Learn how Serverless is billed works and how to optimize your costs.
    </Card>
    <Card title="vLLM quickstart" href="/serverless/vllm/get-started" icon="cloud-bolt" iconType="solid">
        Deploy a large language model for text or image generation in minutes using a vLLM.
    </Card>
    <Card title="Build your first worker" href="/serverless/workers/custom-worker" icon="code" iconType="solid">
        Build a custom worker and deploy it as a Serverless endpoint.
    </Card>
</CardGroup>

## Pods

Pods allow you to run containerized workloads on dedicated GPU or CPU instances.

<CardGroup>
    <Card title="Introduction" href="/pods/overview" icon="microchip" iconType="solid">
        Understand the components of a Pod and options for congiruation.
    </Card>
    <Card title="Choose a Pod" href="/pods/choose-a-pod" icon="server" iconType="solid">
        Learn how to choose the right Pod for your workload.
    </Card>
</CardGroup>

## Support

<Columns cols={3}>
    <Card title="Contact" href="https://contact.runpod.io" icon="headset" iconType="solid">
        Submit a support request using our contact page.
    </Card>
    <Card title="Status page" href="https://uptime.runpod.io/" icon="chart-line" iconType="solid">
        Check the status of RunPod services and infrastructure.
    </Card>
    <Card title="Discord" href="https://discord.gg/cUpRmau42V" icon="discord">
        Join the RunPod community on Discord.
    </Card>
</Columns>
