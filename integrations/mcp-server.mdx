---
title: "Runpod MCP server"
sidebarTitle: "MCP server"
description: "Manage Runpod resources from AI assistants using the Model Context Protocol."
---

The [Runpod MCP server](https://github.com/runpod/runpod-mcp) lets you manage your Runpod infrastructure directly from AI assistants using the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). Instead of switching between the console and your editor, you can create Pods, scale endpoints, manage templates, and more through natural language.

## What you can do

The MCP server exposes tools for managing Pods, Serverless endpoints, templates, network volumes, and container registry authentications. It also provides read-only discovery tools for browsing available GPU types and data centers.

You can perform operations like creating and deleting Pods, scaling Serverless endpoints up and down, listing available GPU types filtered by VRAM or availability, and managing network volumes â€” all through conversational prompts in your AI assistant.

## Supported clients

The server uses stdio transport and works with any MCP-compatible client. This includes Claude Code, Claude Desktop, Cursor, Windsurf, VS Code (GitHub Copilot), Cline, JetBrains IDEs, Zed, and many others. For a full list, see the [official MCP clients page](https://modelcontextprotocol.io/clients).

## Get started

For installation instructions, setup guides for each client, usage examples, and local development information, see the [GitHub repository](https://github.com/runpod/runpod-mcp).

You can also install the server via [Smithery](https://smithery.ai/server/@runpod/runpod-mcp-ts) or directly from npm as `@runpod/mcp-server`.

## Security

The MCP server requires your Runpod API key, which grants full access to your account. Never share your API key or commit it to version control. Consider creating a dedicated API key with limited permissions, and review operations before confirming them, especially deletions.