---
title: "Flash overview"
sidebarTitle: "Overview"
description: "Develop and deploy AI workflows on Runpod Serverless with Python."
---

Flash is a Python SDK for developing and deploying AI workflows on Runpod Serverless. You write Python functions locally, and Flash handles infrastructure management, GPU/CPU provisioning, dependency installation, and data transfer automatically.

Flash provides two ways to run workloads:

- **Standalone scripts**: Use the `@remote` decorator to run Python functions on Runpod cloud infrastructure.
- **API endpoints**: Build and serve HTTP APIs using FastAPI that compute responses with GPU and CPU Serverless workers.

You can find prebuilt Flash examples at [runpod/flash-examples](https://github.com/runpod/flash-examples).

## Why use Flash?

Flash deploys Python functions to Runpod's Serverless infrastructure without requiring you to manage servers, configure networking, or handle scaling. You write functions, specify your dependencies in the decorator, and Flash installs them automatically when the function runs on remote workers.

You can specify the exact GPU hardware you need, from RTX 4090s to A100 80GB GPUs, for AI inference, training, and other compute-intensive tasks. Functions scale automatically based on demand and can run in parallel across multiple workers.

Flash uses Serverless pricing with per-second billing. You're only charged for actual compute time—there are no costs when your code isn't running.

<Card title="Get started" icon="bolt" href="/flash/quickstart">
    Follow the quickstart to create your first Flash function in minutes.
</Card>

## Install Flash

Install Flash with `pip`:

```bash
pip install tetra_rp`.
```

Then configure your Runpod API key as an environment variable.

## Concepts

### Remote functions

The `@remote` decorator marks functions for execution on Runpod's infrastructure. Code inside the decorated function runs remotely on a Serverless worker, while code outside the function runs locally on your machine.

```python
@remote(resource_config=config, dependencies=["pandas"])
def process_data(data):
    # This code runs remotely on Runpod
    import pandas as pd
    df = pd.DataFrame(data)
    return df.describe().to_dict()

async def main():
    # This code runs locally
    result = await process_data(my_data)
```

### Resource configuration

Flash provides fine-grained control over hardware allocation through configuration objects. You can configure GPU types, worker counts, idle timeouts, environment variables, and more.

```python
from tetra_rp import LiveServerless, GpuGroup

gpu_config = LiveServerless(
    name="ml-inference",
    gpus=[GpuGroup.AMPERE_80],  # A100 80GB
    workersMax=5
)
```

### Dependency management

Specify Python packages in the decorator, and Flash installs them automatically on the remote worker:

```python
@remote(
    resource_config=gpu_config,
    dependencies=["transformers==4.36.0", "torch", "pillow"]
)
def generate_image(prompt):
    # Import inside the function
    from transformers import pipeline
    # ...
```

Imports should be placed inside the function body because they need to happen on the remote worker, not in your local environment.

### Parallel execution

Run multiple remote functions concurrently using Python's async capabilities:

```python
results = await asyncio.gather(
    process_item(item1),
    process_item(item2),
    process_item(item3)
)
```

## How it works

Flash orchestrates workflow execution through a multi-step process:

1. **Function identification**: The `@remote` decorator marks functions for remote execution, enabling Flash to distinguish between local and remote operations.
2. **Dependency analysis**: Flash automatically analyzes function dependencies to construct an optimal execution order.
3. **Resource provisioning and execution**: For each remote function, Flash:
   - Dynamically provisions endpoint and worker resources on Runpod's infrastructure.
   - Serializes and securely transfers input data to the remote worker.
   - Executes the function on the remote infrastructure with the specified GPU or CPU resources.
   - Returns results to your local environment.
4. **Data orchestration**: Results flow seamlessly between functions according to your local Python code structure.

## Use cases

Flash is well-suited for a range of AI and data processing workloads:

- **Multi-modal AI pipelines**: Orchestrate unified workflows combining text, image, and audio models with GPU acceleration.
- **Distributed model training**: Scale training operations across multiple GPU workers for faster model development.
- **AI research experimentation**: Rapidly prototype and test complex model combinations without infrastructure overhead.
- **Production inference systems**: Deploy multi-stage inference pipelines for real-world applications.
- **Data processing workflows**: Process large datasets using CPU workers for general computation and GPU workers for accelerated tasks.
- **Hybrid GPU/CPU workflows**: Optimize cost and performance by combining CPU preprocessing with GPU inference.

## Development workflow

A typical Flash development workflow looks like this:

1. Write Python functions with the `@remote` decorator.
2. Specify resource requirements and dependencies in the decorator.
3. Run your script locally—Flash handles remote execution automatically.
4. For API deployments, use `flash init` to create a project and `flash run` to start your server.

## Limitations

- Serverless deployments using Flash are currently restricted to the `EU-RO-1` datacenter.
- Flash is designed primarily for local development and live-testing workflows.
- Endpoints created by Flash persist until manually deleted through the Runpod console. A `flash undeploy` command is in development.
- Be aware of your account's maximum worker capacity limits. Flash can rapidly scale workers across multiple endpoints, and you may hit capacity constraints. Contact Runpod support to increase your account's capacity allocation if needed.

## Next steps

<CardGroup cols={2}>
  <Card title="Quickstart" href="/flash/quickstart" icon="bolt">
    Get started with your first Flash function.
  </Card>
  <Card title="Create remote functions" href="/flash/remote-functions" icon="code">
    Learn about resource configuration, dependencies, and parallel execution.
  </Card>
  <Card title="Create API endpoints" href="/flash/api-endpoints" icon="server">
    Build HTTP APIs with FastAPI and Flash.
  </Card>
  <Card title="Configuration reference" href="/flash/resource-configuration" icon="sliders">
    Complete reference for resource configuration options.
  </Card>
</CardGroup>
